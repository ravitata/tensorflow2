{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravitata/tensorflow2/blob/master/c2w4_Coding_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjBj_lcNHM8K",
        "outputId": "ad15328b-ca7d-4566-fd99-c6c636842247"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQpjnvOGHM8O"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEqjxbvrHM8P"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_sUK7I5HM8P"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "annr4IU4HM8P"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jK7RBxkHM8P"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3urxYgXrHM8P"
      },
      "source": [
        "# Build the model #1\n",
        "class MyModel(Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyModel, self).__init__(**kwargs)\n",
        "    self.dense_1=Dense(64, activation='relu')\n",
        "    self.dense_2=Dense(10)\n",
        "    self.dropout = Dropout(0.4)\n",
        "  \n",
        "  def call(self, inputs, training = True):\n",
        "    d = self.dense_1(inputs)\n",
        "    if training:\n",
        "      d = self.dropout(d)\n",
        "    return self.dense_2(d)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWcv1WvHHM8Q",
        "outputId": "c322eae4-edfa-4ec7-c5e4-5dc546208c4a"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1, 10]), True)\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  650       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_eLfPrj1EXR",
        "outputId": "04ddeb36-d7c4-43e9-9cd5-8a499515c11e"
      },
      "source": [
        "print(10*64+64)\n",
        "print(64*10+10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "704\n",
            "650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxqv2N0r0EVd"
      },
      "source": [
        "# Build the model #2\n",
        "class MyModel(Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyModel, self).__init__(**kwargs)\n",
        "    self.dense_1=Dense(64, activation='relu')\n",
        "    self.dense_2=Dense(10)\n",
        "    self.dense_3=Dense(5)\n",
        "    self.softmax = Softmax()\n",
        "  \n",
        "  def call(self, inputs, training = True):\n",
        "    dl1 = self.dense_1(inputs)\n",
        "    dl2 = self.dense_2(inputs)\n",
        "    dl3 = self.dense_3(dl2)\n",
        "    return self.softmax(concatenate([dl1, dl3]))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCHEzAlX0k8m",
        "outputId": "942c2424-a334-4d5c-8fb5-ef3907cef30b"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1, 10]))\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VisJkt0i1UTq",
        "outputId": "5112abff-b761-416d-e996-a18497c75b16"
      },
      "source": [
        "print(10*64+64)\n",
        "print(10*10+10)\n",
        "print(10*5+5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "704\n",
            "110\n",
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFOEp29hHM8Q"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjOh3jcVMkD5",
        "outputId": "49ce0aa5-9a3f-42d3-df13-d089d9e9b633"
      },
      "source": [
        "print(tf.ones((3,))*0.1)\n",
        "print(tf.ones((2,3)))\n",
        "print(tf.reduce_sum(tf.ones((2,3)), axis=0))\n",
        "\n",
        "print(tf.ones((3,))*0.1+tf.ones((2,3)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.1 0.1 0.1], shape=(3,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor([2. 2. 2.], shape=(3,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1.1 1.1 1.1]\n",
            " [1.1 1.1 1.1]], shape=(2, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_Xs7JiHM8Q"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWDRH98xHM8Q"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5iIIWNIHM8R",
        "outputId": "926d5e51-1840-4744-e99d-86acb4174666"
      },
      "source": [
        "# Create a custom layer\n",
        "class MyLayer(Layer):\n",
        "  def __init__(self, units, input_dims, **kwargs):\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "    self.w = self.add_weight(shape=(input_dims, units),\n",
        "                              initializer = 'random_normal')\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                              initializer = 'zeros')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "dense_layer = MyLayer(3, 5)\n",
        "x = tf.ones([3, 5])\n",
        "print(dense_layer(x))\n",
        "print()\n",
        "print(dense_layer.weights)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.31820598 -0.19529817  0.10343248]\n",
            " [-0.31820598 -0.19529817  0.10343248]\n",
            " [-0.31820598 -0.19529817  0.10343248]], shape=(3, 3), dtype=float32)\n",
            "\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[-0.0819759 , -0.04058618, -0.00326149],\n",
            "       [-0.04040538,  0.00889558,  0.04144095],\n",
            "       [-0.04062394, -0.0637196 ,  0.0299923 ],\n",
            "       [-0.07350152, -0.00281865,  0.02475185],\n",
            "       [-0.08169924, -0.09706932,  0.01050888]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y24kLYAHM8R"
      },
      "source": [
        "# Specify trainable weights\n",
        "# Create a custom layer\n",
        "class MyLayer(Layer):\n",
        "  def __init__(self, units, input_dims, **kwargs):\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "    self.w = self.add_weight(shape=(input_dims, units),\n",
        "                             initializer = 'random_normal',\n",
        "                             trainable=False)\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer = 'zeros',\n",
        "                             trainable=False)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w)+self.b\n",
        "\n",
        "dense_layer = MyLayer(3, 5)\n",
        "x = tf.ones([3, 5])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rf8hDOtHM8R",
        "outputId": "19a8ec9d-1a8c-4429-ca0b-6000fbc52234"
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlB4i72WHM8R"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyAccuLayer(Layer):\n",
        "  def __init__(self, units, input_dims, **kwargs):\n",
        "    super(MyAccuLayer, self).__init__(**kwargs)\n",
        "    self.w = self.add_weight(shape=(input_dims, units),\n",
        "                             initializer = 'random_normal',\n",
        "                             trainable=True)\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer = 'zeros',\n",
        "                             trainable=True)\n",
        "    self.sum_activations = tf.Variable(initial_value=tf.zeros(units, 1),\n",
        "                                       trainable = False)\n",
        "    self.sum_numbercalls = tf.Variable(initial_value=0,\n",
        "                                       trainable = False)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    activations = tf.matmul(inputs, self.w) + self.b\n",
        "    self.sum_activations.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "    self.sum_numbercalls.assign_add(inputs.shape[0])\n",
        "    return activations, self.sum_activations/tf.cast(self.sum_numbercalls, dtype=tf.float32)\n",
        "\n",
        "dense_layer = MyAccuLayer(3, 5)\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WPHkfATHM8R",
        "outputId": "c81410a4-c9ab-49c3-98b6-37e87fc46f13"
      },
      "source": [
        "# Test the layer\n",
        "#print(dense_layer.weights)\n",
        "\n",
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((4, 5)))\n",
        "#print(y)\n",
        "print(activation_means.numpy())\n",
        "\n",
        "#print(dense_layer.weights)\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((4, 5)))\n",
        "#print(y)\n",
        "print(activation_means.numpy())\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 2\n",
            "non-trainable weights: 2\n",
            "[-0.04860301 -0.1812087   0.01455377]\n",
            "[-0.04860301 -0.1812087   0.01455377]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bodt3zmsHM8R"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbdcSkWHM8S"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFAhhrm_HM8S"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7KsSVAbHM8S",
        "outputId": "0a0a7f27-d41e-4fd4-a35f-f03a6ea891b7"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.02090953 0.01142974 0.07456445 0.02190891 0.02674391 0.0110913\n",
            "  0.02386488 0.01485288 0.01164801 0.01920787 0.01839604 0.02217719\n",
            "  0.01752604 0.01667207 0.0230643  0.02906349 0.00564318 0.00926722\n",
            "  0.01871433 0.00868067 0.00596352 0.05895493 0.01625041 0.02460447\n",
            "  0.02909585 0.01187052 0.03093156 0.01206623 0.0373578  0.01536121\n",
            "  0.0099079  0.04342087 0.0545307  0.00840314 0.01659922 0.01188985\n",
            "  0.01811597 0.00832332 0.02042322 0.01099269 0.06727993 0.00644852\n",
            "  0.0194832  0.01279305 0.01214346 0.03136239]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_22 (MyLayer)        multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_6 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_23 (MyLayer)        multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_7 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_24 (MyLayer)        multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_3 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 0\n",
            "Non-trainable params: 647,214\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E_sb_6gHM8S"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6_A-Hg6HM8S"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NeQ6VmtHM8S"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "EaiPuNkEHM8S",
        "outputId": "d5b08943-2774-4c58-972b-e5c9aea9254d"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9553201160>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNjH5ygqHM8T"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZF7iHG5HM8T"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hStnlGCHM8T",
        "outputId": "a0692d94-6b03-4185-efde-1711ec722b0b"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class MyLinearLayer(Layer):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(MyLinearLayer, self).__init__()\n",
        "    self.m = self.add_weight(shape=(1,),\n",
        "                              initializer='random_normal')\n",
        "    self.b = self.add_weight(shape=(1,),\n",
        "                              initializer='zeros')  \n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return self.m * inputs + self.b\n",
        "\n",
        "linear_regression = MyLinearLayer()\n",
        "print(linear_regression(x_train))\n",
        "print(x_train)\n",
        "print(linear_regression.weights)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.00133782 0.01935308 0.01251462 0.01509684 0.01380814 0.00495006\n",
            " 0.02405855 0.02461202 0.009515   0.01624025 0.00520578 0.02737495\n",
            " 0.02530224 0.00284143 0.02796365 0.00966123 0.01779484 0.02483832\n",
            " 0.03047877 0.02256697], shape=(20,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[0.04380739 0.6337229  0.40979528 0.4943509  0.452152   0.16209126\n",
            " 0.7878052  0.8059286  0.31157196 0.5317923  0.17046487 0.8964019\n",
            " 0.8285303  0.09304357 0.915679   0.31636024 0.582698   0.813339\n",
            " 0.9980372  0.73896277], shape=(20,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.03053871], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVU68yavww9f",
        "outputId": "cdea9815-cfee-4a1b-df7b-4d38f21bb416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mx+b\n",
        "0.03053871 * 0.6337229 + 0"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019353079863459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3CnvsvzHM8T"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mKcmNdXHM8T",
        "outputId": "7d2378c8-5b3e-4bda-849c-aba2b02a1ecb"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.360185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKBObrvTHM8T"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JuAAwvvHM8T",
        "outputId": "53cce36f-c628-4e1f-f1e5-82e636f97a60"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = linear_regression(x_train)\n",
        "    loss = SquaredError(predictions, y_train)\n",
        "  \n",
        "  gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "  linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
        "  linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "  print('Step %d Loss %f'%(i, loss.numpy()))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 Loss 6.360185\n",
            "Step 1 Loss 4.792069\n",
            "Step 2 Loss 3.611174\n",
            "Step 3 Loss 2.721879\n",
            "Step 4 Loss 2.052176\n",
            "Step 5 Loss 1.547838\n",
            "Step 6 Loss 1.168030\n",
            "Step 7 Loss 0.882000\n",
            "Step 8 Loss 0.666590\n",
            "Step 9 Loss 0.504362\n",
            "Step 10 Loss 0.382182\n",
            "Step 11 Loss 0.290161\n",
            "Step 12 Loss 0.220852\n",
            "Step 13 Loss 0.168647\n",
            "Step 14 Loss 0.129321\n",
            "Step 15 Loss 0.099695\n",
            "Step 16 Loss 0.077374\n",
            "Step 17 Loss 0.060553\n",
            "Step 18 Loss 0.047875\n",
            "Step 19 Loss 0.038316\n",
            "Step 20 Loss 0.031107\n",
            "Step 21 Loss 0.025667\n",
            "Step 22 Loss 0.021560\n",
            "Step 23 Loss 0.018457\n",
            "Step 24 Loss 0.016109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "lB4VNcL5HM8U",
        "outputId": "515c25ab-de7e-4a41-f7e8-a41d6d58e004"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[1.0727534]\n",
            "b:2,  trained b:[1.856056]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f954ac45160>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Km9nO-HM8U"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMQvw3KHM8U"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzoVC5HM8U"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xGjfiF4HM8U"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oza0xz7GHM8U"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_qsQBwaHM8U"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJlWebBvHM8U"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4rC88rjHM8V"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4dXUAk3HM8V"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30CSww-AHM8V"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8-AHwOWHM8V"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po0EiM8uHM8V"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAMys-wGHM8V"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q7slLT2HM8V"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrSpjtyJHM8W"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75T0hHF1HM8W"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYJwyDkEHM8W"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC6xAhhhHM8W"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwXL2UYfHM8X"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2c4xxjCHM8X"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Y1baQdHM8X"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wPqAQgyHM8X"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPLc8fwbHM8X"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9HJn1LBHM8X"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvO_8B9kHM8X"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkj4Urq0HM8Y"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFUGonqUHM8Y"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcIY3Wp7HM8Y"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGgpMMK6HM8Y"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A46Y_w7hHM8Y"
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmRksHUYHM8Y"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0142NkFHM8Y"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyiI52yEHM8Y"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVX6PCGtHM8Z"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZgd3af1HM8Z"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zCoSlxWHM8Z"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}