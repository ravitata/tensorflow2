{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "slDi0LNSLwlk",
        "1tPbAdRYLwmH",
        "YLOK8GMOLwmP",
        "KA-VnvRpLwmW",
        "-djfT1vDLwma",
        "wxB-r6_sLwmd",
        "eASEXb7uLwml",
        "CndbEe9-Lwmw",
        "2PTkNo-uLwm-",
        "tyi9F1cRLwnF",
        "KUfxD0WHLwnU",
        "8lDJvPvfLwnd",
        "IuICkLdgLwnv",
        "EdlrTTxkLwn1",
        "LoxWasQKLwn5",
        "zS5yD7TaLwn7",
        "vqqV3Ox9LwoA",
        "5d8X74-yLwoL",
        "agL_w4bhLwoU",
        "EgdUwwomLwom",
        "FJWNhXxMLwov",
        "WDGZ4VF-LwpC",
        "PDCxC62VLwpF",
        "B0IxwSLpLwpN",
        "8Ljy2Ro9LwpS",
        "5z_etyCZLwpZ",
        "H7rFrXSkLwpf",
        "waZerBcdLwpj",
        "6euItJ8bLwpn"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravitata/tensorflow2/blob/master/c2w2_Coding_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JsB_bKALwj0"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT-hyAgFLwj7"
      },
      "source": [
        "# Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ueZW9CLwj8"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Keras datasets](#coding_tutorial_1)\n",
        " #### [2. Dataset generators](#coding_tutorial_2)\n",
        " #### [3. Keras image data augmentation](#coding_tutorial_3)\n",
        " #### [4. The Dataset class](#coding_tutorial_4)\n",
        " #### [5. Training with Datasets](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF-0r_trLwj9"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Keras datasets\n",
        "\n",
        "For a list of Keras datasets and documentation on recommended usage, see [this link](https://keras.io/datasets/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHF_JbgGLwj-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyE5HuD8LwkB"
      },
      "source": [
        "#### Load the CIFAR-100 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Flu2zSLwkC"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SQUmYRQdLwkF"
      },
      "source": [
        "# Load the CIFAR-100 dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l75ozQVFLwkI"
      },
      "source": [
        "# Confirm that reloading the dataset does not require a download\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1UEPzrYLwkL"
      },
      "source": [
        "#### Examine the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDYN-cq9Mc2Q"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The additional files required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "cifar100_fine_labels: https://drive.google.com/open?id=1WFW1cj8v_5z1pGvq6htQyFUPrJP-Z2v5\n",
        "\n",
        "cifar100_coarse_labels: https://drive.google.com/open?id=1Jmt7o-6sP85D7iRORk5tJqJMN3wCP12p\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiplZnP2ND6o"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpkIbhLTLwkM"
      },
      "source": [
        "# Examine the shape of the data.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY58jmf5LwkS"
      },
      "source": [
        "# Examine one of the images and its corresponding label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bojn7VsfLwkV"
      },
      "source": [
        "# Load the list of labels from a JSON file\n",
        "\n",
        "import json\n",
        "\n",
        "with open('path/to/cifar100_fine_labels.json', 'r') as fine_labels:\n",
        "    cifar100_fine_labels = json.load(fine_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcULe51BLwkZ"
      },
      "source": [
        "The list of labels for the CIFAR-100 dataset are available [here](https://www.cs.toronto.edu/~kriz/cifar.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXq95zzcLwka"
      },
      "source": [
        "# Print a few of the labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Oqo7xKLwkd"
      },
      "source": [
        "# Print the corresponding label for the example above\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKQA_qggLwkh"
      },
      "source": [
        "#### Load the data using different label modes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkLZ3caeLwki"
      },
      "source": [
        "# Display a few examples from category 87 (index 86) and the list of labels\n",
        "\n",
        "examples = train_images[(train_labels.T == 86)[0]][:3]\n",
        "fig, ax = plt.subplots(1,3)\n",
        "ax[0].imshow(examples[0])\n",
        "ax[1].imshow(examples[1])\n",
        "ax[2].imshow(examples[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdP2x7rFLwkk"
      },
      "source": [
        "# Reload the data using the 'coarse' label mode\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVizCMTSLwkn"
      },
      "source": [
        "# Display three images from the dataset with the label 6 (index 5)\n",
        "\n",
        "examples = train_images[(train_labels.T == 5)[0]][:3]\n",
        "fig, ax = plt.subplots(1,3)\n",
        "ax[0].imshow(examples[0])\n",
        "ax[1].imshow(examples[1])\n",
        "ax[2].imshow(examples[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_MZIWCFLwks"
      },
      "source": [
        "# Load the list of coarse labels from a JSON file\n",
        "\n",
        "with open('path/to/cifar100_coarse_labels.json', 'r') as coarse_labels:\n",
        "    cifar100_coarse_labels = json.load(coarse_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wbvYhD48Lwku"
      },
      "source": [
        "# Print a few of the labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KGMaEInLwkx"
      },
      "source": [
        "# Print the corresponding label for the example above\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZDJui8OLwk1"
      },
      "source": [
        "#### Load the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKylrcBKLwk2"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWNp9BGZLwk4"
      },
      "source": [
        "# Load the IMDB dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTHEOfQ1Lwk8"
      },
      "source": [
        "# Print an example from the training dataset, along with its corresponding label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikjKYS5Lwk-"
      },
      "source": [
        "# Get the lengths of the input sequences\n",
        "\n",
        "sequence_lengths = [len(seq) for seq in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QbK1eZOLwlB"
      },
      "source": [
        "# Determine the maximum and minimum sequence length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfxdEsETLwlD"
      },
      "source": [
        "#### Using Keyword Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_rJ9cHDLwlE"
      },
      "source": [
        "# Load the data ignoring the 50 most frequent words, use oov_char=2 (this is the default)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfrBgZWXLwlH"
      },
      "source": [
        "# Get the lengths of the input sequences\n",
        "\n",
        "sequence_lengths = [len(seq) for seq in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqSdCKqxLwlJ"
      },
      "source": [
        "# Determine the maximum and minimum sequence length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9RjMJaJLwlL"
      },
      "source": [
        "# Define functions for filtering the sequences\n",
        "\n",
        "def remove_oov_char(element):\n",
        "    ''' Filter function for removing the oov_char. '''\n",
        "    return [word for word in element if word!=2]\n",
        "\n",
        "def filter_list(lst):\n",
        "    ''' Run remove_oov_char on elements in a list. '''\n",
        "    return [remove_oov_char(element) for element in lst]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eBoicx1LwlO"
      },
      "source": [
        "# Remove the oov_char from the sequences using the filter_list function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ0myFkyLwlR"
      },
      "source": [
        "# Get the lengths of the input sequences\n",
        "\n",
        "sequence_lengths = [len(seq) for seq in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy5jFTr3LwlU"
      },
      "source": [
        "# Determine the maximum and minimum sequence length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43w36xfNLwlW"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Dataset generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GVjAo5nLwlX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeksQNB9LwlZ"
      },
      "source": [
        "#### Load the UCI Fertility Dataset\n",
        "\n",
        "We will be using a dataset available at https://archive.ics.uci.edu/ml/datasets/Fertility from UC Irvine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDMv0Yc6NGd9"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1OA0lwa5YLDs1njS377jbqPpMSlH5TzQV\n",
        "\n",
        "You should store this file in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-HCBxlNGpb"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKfmk3zpLwla"
      },
      "source": [
        "# Load the fertility dataset\n",
        "\n",
        "headers = ['Season', 'Age', 'Diseases', 'Trauma', 'Surgery', 'Fever', 'Alcohol', 'Smoking', 'Sitting', 'Output']\n",
        "fertility = pd.read_csv('path/to/fertility_diagnosis.txt', delimiter=',', header=None, names=headers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWOyjhCJLwld"
      },
      "source": [
        "# Print the shape of the DataFrame\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwGWKnbbLwlf"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slDi0LNSLwlk"
      },
      "source": [
        "#### Process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCmzD-5HLwll"
      },
      "source": [
        "# Map the 'Output' feature from 'N' to 0 and from 'O' to 1\n",
        "\n",
        "fertility['Output'] = fertility['Output'].map(lambda x : 0.0 if x=='N' else 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yjVX1KMLwlo"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ5qjO5ALwlq"
      },
      "source": [
        "# Convert the DataFrame so that the features are mapped to floats\n",
        "\n",
        "fertility = fertility.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWIZ-en6Lwls"
      },
      "source": [
        "# Shuffle the DataFrame\n",
        "\n",
        "fertility = fertility.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4HH_ObWqLwlu"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oREiQC5wLwly"
      },
      "source": [
        "# Convert the field Season to a one-hot encoded vector\n",
        "\n",
        "fertility = pd.get_dummies(fertility, prefix='Season', columns=['Season'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCUdq3VLwl2"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eukmHFMILwl5"
      },
      "source": [
        "# Move the Output column such that it is the last column in the DataFrame\n",
        "\n",
        "fertility.columns = [col for col in fertility.columns if col != 'Output'] + ['Output']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-anaeBLLwmB"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEyYKSueLwmD"
      },
      "source": [
        "# Convert the DataFrame to a numpy array.\n",
        "\n",
        "fertility = fertility.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tPbAdRYLwmH"
      },
      "source": [
        "#### Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1qYU7lcLwmI"
      },
      "source": [
        "# Split the dataset into training and validation set\n",
        "\n",
        "training = fertility[0:70]\n",
        "validation = fertility[70:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnwFqRrLLwmL"
      },
      "source": [
        "# Verify the shape of the training data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvCdYLU5LwmN"
      },
      "source": [
        "# Separate the features and labels for the validation and training data\n",
        "\n",
        "training_features = training[:,0:-1]\n",
        "training_labels = training[:,-1]\n",
        "validation_features = validation[:,0:-1]\n",
        "validation_labels = validation[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLOK8GMOLwmP"
      },
      "source": [
        "#### Create the Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uINAoFn5LwmQ"
      },
      "source": [
        "# Create a function that returns a generator producing inputs and labels\n",
        "\n",
        "def get_generator(features, labels, batch_size=1):\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_zKx3oJLwmS"
      },
      "source": [
        "# Apply the function to our training features and labels with a batch size of 10\n",
        "\n",
        "train_generator = get_generator(training_features, training_labels, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y3jCTRuLwmT"
      },
      "source": [
        "# Test the generator using the next() function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA-VnvRpLwmW"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5T3dXGZLwmW"
      },
      "source": [
        "# Create a model using Keras with 3 layers\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
        "\n",
        "input_shape = (12,)\n",
        "output_shape = (1,)\n",
        "\n",
        "model_input = Input(input_shape)\n",
        "batch_1 = BatchNormalization(momentum=0.8)(model_input)\n",
        "dense_1 = Dense(100, activation='relu')(batch_1)\n",
        "batch_2 = BatchNormalization(momentum=0.8)(dense_1)\n",
        "output = Dense(1, activation='sigmoid')(batch_2)\n",
        "\n",
        "model = Model([model_input], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCBoGMMULwmY"
      },
      "source": [
        "# Display the model summary to show the resultant structure\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-djfT1vDLwma"
      },
      "source": [
        "#### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_PyDixLLwma"
      },
      "source": [
        "# Create the optimizer object\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZUjV3LpLwmc"
      },
      "source": [
        "# Compile the model with loss function and metric\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxB-r6_sLwmd"
      },
      "source": [
        "#### Train and evaluate the model using the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCmNFC0eLwmd"
      },
      "source": [
        "# Calculate the number of training steps per epoch for the given batch size.\n",
        "\n",
        "batch_size = 5\n",
        "train_steps = len(training) // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCyaX46bLwmf"
      },
      "source": [
        "# Set the epochs to 3\n",
        "\n",
        "epochs = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TKc7muJLwmg"
      },
      "source": [
        "# Train the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5-6hh7BsLwmj"
      },
      "source": [
        "# Try to run the fit_generator function once more; observe what happens\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eASEXb7uLwml"
      },
      "source": [
        "#### Make an infinitely looping generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX2TZzl2Lwmm"
      },
      "source": [
        "# Create a function that returns an infinitely looping generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkZIx02TLwmo"
      },
      "source": [
        "# Create a generator using this function.\n",
        "\n",
        "train_generator_cyclic = get_generator_cyclic(training_features, training_labels, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCXB7YBZLwmr"
      },
      "source": [
        "# Assert that the new cyclic generator does not raise a StopIteration\n",
        "\n",
        "for i in range(2*train_steps):\n",
        "    next(train_generator_cyclic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJXeBNFALwms"
      },
      "source": [
        "# Generate a cyclic validation generator\n",
        "\n",
        "validation_generator_cyclic = get_generator_cyclic(validation_features, validation_labels, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-ezRy60iLwmu"
      },
      "source": [
        "# Train the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CndbEe9-Lwmw"
      },
      "source": [
        "#### Evaluate the model and get predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAPuIgstLwmw"
      },
      "source": [
        "# Let's obtain a validation data generator.\n",
        "\n",
        "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs38y9RaLwmz"
      },
      "source": [
        "# Get predictions on the validation data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4Ce17XxwLwm4"
      },
      "source": [
        "# Print the corresponding validation labels\n",
        "\n",
        "print(validation_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUUeWVS1Lwm6"
      },
      "source": [
        "# Obtain a validation data generator\n",
        "\n",
        "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shBJD8w4Lwm7"
      },
      "source": [
        "# Evaluate the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgEaDU0TLwm8"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Keras image data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fea1o5zdlS0p"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=11Y43ta5gT672L3sfJFR2DvPs-ralY5Pd\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPDIjLB8lW6v"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdw6c9W-Lwm8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PTkNo-uLwm-"
      },
      "source": [
        "#### Load the CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-174tvQULwm-"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_ipqjVnLwnA"
      },
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "\n",
        "(training_features, training_labels), (test_features, test_labels) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH-q30M2LwnC"
      },
      "source": [
        "# Convert the labels to a one-hot encoding\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyi9F1cRLwnF"
      },
      "source": [
        "#### Create a generator function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiTmYP9HLwnF"
      },
      "source": [
        "# Create a function that returns a data generator\n",
        "\n",
        "def get_generator(features, labels, batch_size=1):\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield (features[n*batch_size:(n+1)*batch_size], labels[n*batch_size:(n+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXXF9JKNLwnI"
      },
      "source": [
        "# Use the function we created to get a training data generator with a batch size of 1\n",
        "\n",
        "training_generator = get_generator(training_features, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaflrvQYLwnL"
      },
      "source": [
        "# Assess the shape of the items generated by training_generator using the `next` function to yield an item.\n",
        "\n",
        "image, label = next(training_generator)\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXS3YwfdLwnQ"
      },
      "source": [
        "# Test the training generator by obtaining an image using the `next` generator function, and then using imshow to plot it.\n",
        "# Print the corresponding label\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "image, label = next(training_generator)\n",
        "image_unbatched = image[0,:,:,:]\n",
        "imshow(image_unbatched)\n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRHQU5fyLwnS"
      },
      "source": [
        "# Reset the generator by re-running the `get_generator` function.\n",
        "\n",
        "train_generator = get_generator(training_features, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUfxD0WHLwnU"
      },
      "source": [
        "#### Create a data augmention generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S209JxdNLwnU"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R80OSZxoLwnX"
      },
      "source": [
        "# Create a function to convert an image to monochrome\n",
        "\n",
        "def monochrome(x):\n",
        "    def func_bw(a):\n",
        "        average_colour = np.mean(a)\n",
        "        return [average_colour, average_colour, average_colour]\n",
        "    x = np.apply_along_axis(func_bw, -1, x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B_-LrD8LwnZ"
      },
      "source": [
        "# Create an ImageDataGenerator object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wheasgOSLwna"
      },
      "source": [
        "Check [the documentation](https://keras.io/preprocessing/image/) for the full list of image data augmentation options. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElwkY6hzLwna"
      },
      "source": [
        "# Create an iterable generator using the `flow` function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "G_MojVrRLwnc"
      },
      "source": [
        "# Show a sample from the generator and compare with the original\n",
        "\n",
        "image, label = next(image_generator_iterable)\n",
        "image_orig, label_orig = next(train_generator)\n",
        "figs, axes = plt.subplots(1,2)\n",
        "axes[0].imshow(image[0,:,:,:])\n",
        "axes[0].set_title('Transformed')\n",
        "axes[1].imshow(image_orig[0,:,:,:])\n",
        "axes[1].set_title('Original')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lDJvPvfLwnd"
      },
      "source": [
        "#### Flow from directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0sOke4dLwne"
      },
      "source": [
        "# Inspect the directory structure\n",
        "\n",
        "train_path = 'path/to/flowers-recognition-split/train'\n",
        "val_path = 'path/to/flowers-recognition-split/val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU_0lGLnLwnf"
      },
      "source": [
        "# Create an ImageDataGenerator object\n",
        "\n",
        "datagenerator = ImageDataGenerator(rescale=(1/255.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSTFnZpLwng"
      },
      "source": [
        "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoSrRM2vLwni"
      },
      "source": [
        "# Create a training data generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4iABrtkLwnj"
      },
      "source": [
        "# Create a validation data generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xttbpzhiLwnn"
      },
      "source": [
        "# Get and display an image and label from the training generator\n",
        "\n",
        "x = next(train_generator)\n",
        "imshow(x[0][4])\n",
        "print(x[1][4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eubMyZu7Lwnu"
      },
      "source": [
        "# Reset the training generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuICkLdgLwnv"
      },
      "source": [
        "#### Create a model to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Vli6KboxLwnv"
      },
      "source": [
        "# Build a CNN model\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Input((16,16,3)))\n",
        "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((4,4)))\n",
        "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(4, (4, 4), padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EpyPWDtLwnw"
      },
      "source": [
        "# Create an optimizer object\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkzxS4w8Lwny"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRFuAO0dLwnz"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdlrTTxkLwn1"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cXhw2VhLwn1"
      },
      "source": [
        "# Calculate the training generator and test generator steps per epoch\n",
        "\n",
        "train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
        "val_steps = val_generator.n // val_generator.batch_size\n",
        "print(train_steps_per_epoch, val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3daJBkILwn4"
      },
      "source": [
        "# Fit the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoxWasQKLwn5"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-85jqQXiLwn6"
      },
      "source": [
        "# Evaluate the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS5yD7TaLwn7"
      },
      "source": [
        "#### Predict using the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz3CsLtgLwn8"
      },
      "source": [
        "# Predict labels with the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW1KSTrfLwn_"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB1fIrr8lmUb"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1BAjGPFlpqsDdWof50Ng3Fmju5O8F1_uZ\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfnXkSB3lmek"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xONz3oFLwn_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqqV3Ox9LwoA"
      },
      "source": [
        "#### Create a simple dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7i5Nkm6LwoA"
      },
      "source": [
        "x = np.zeros((100,10,2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRIbPGW0LwoC"
      },
      "source": [
        "# Create a dataset from the tensor x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPIBuRAPLwoE"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwXTdMGYLwoF"
      },
      "source": [
        "x2 = [np.zeros((10,2,2)), np.zeros((5,2,2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u33v-mOtLwoG"
      },
      "source": [
        "# Try creating a dataset from the tensor x2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlwcxydiLwoH"
      },
      "source": [
        "x2 = [np.zeros((10,1)), np.zeros((10,1)), np.zeros((10,1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWA_WwA9LwoI"
      },
      "source": [
        "# Create another dataset from the new x2 and inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaAx8T-8LwoK"
      },
      "source": [
        "# Print the element_spec\n",
        "\n",
        "print(dataset2.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d8X74-yLwoL"
      },
      "source": [
        "#### Create a zipped dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pll2VDVALwoM"
      },
      "source": [
        "# Combine the two datasets into one larger dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFMyovAFLwoO"
      },
      "source": [
        "# Print the element_spec\n",
        "\n",
        "print(dataset_zipped.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKlzGVR-LwoQ"
      },
      "source": [
        "# Define a function to find the number of batches in a dataset\n",
        "\n",
        "def get_batches(dataset):\n",
        "    iter_dataset = iter(dataset)\n",
        "    i = 0\n",
        "    try:\n",
        "        while next(iter_dataset):\n",
        "            i = i+1\n",
        "    except:\n",
        "        return i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pN5h3VbLwoS"
      },
      "source": [
        "# Find the number of batches in the zipped Dataset\n",
        "\n",
        "get_batches(dataset_zipped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agL_w4bhLwoU"
      },
      "source": [
        "#### Create a dataset from numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8BG27uVLwoU"
      },
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "(train_features, train_labels), (test_features, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(type(train_features), type(train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9z_XKC5LwoX"
      },
      "source": [
        "# Create a Dataset from the MNIST data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2huRDyELwob"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n",
        "print(mnist_dataset.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYy7jUxxLwog"
      },
      "source": [
        "# Inspect the length of an element using the take method\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmU3DT_0Lwok"
      },
      "source": [
        "# Examine the shapes of the data\n",
        "\n",
        "print(element[0].shape)\n",
        "print(element[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgdUwwomLwom"
      },
      "source": [
        "#### Create a dataset from text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc2ox0fXLwon"
      },
      "source": [
        "# Print the list of text files\n",
        "\n",
        "text_files = sorted([f.path for f in os.scandir('path/to/shakespeare')])\n",
        "\n",
        "print(text_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K91kV97kLwoo"
      },
      "source": [
        "# Load the first file using python and print the first 5 lines.\n",
        "\n",
        "with open(text_files[0], 'r') as fil:\n",
        "    contents = [fil.readline() for i in range(5)]\n",
        "    for line in contents:\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MMqVhxNLwop"
      },
      "source": [
        "# Load the lines from the files into a dataset using TextLineDataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEM2up5CLwoq"
      },
      "source": [
        "# Use the take method to get and print the first 5 lines of the dataset\n",
        "\n",
        "first_5_lines_dataset = iter(shakespeare_dataset.take(5))\n",
        "lines = [line for line in first_5_lines_dataset]\n",
        "for line in lines:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t06mXu1oLwor"
      },
      "source": [
        "# Compute the number of lines in the first file\n",
        "\n",
        "lines = []\n",
        "with open(text_files[0], 'r') as fil:\n",
        "    line = fil.readline()\n",
        "    while line:\n",
        "        lines.append(line)\n",
        "        line = fil.readline()\n",
        "    print(len(lines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS3TysHqLwot"
      },
      "source": [
        "# Compute the number of lines in the shakespeare dataset we created\n",
        "\n",
        "shakespeare_dataset_iterator = iter(shakespeare_dataset)\n",
        "lines = [line for line in shakespeare_dataset_iterator]\n",
        "print(len(lines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJWNhXxMLwov"
      },
      "source": [
        "#### Interleave lines from the text data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "n7ukqFrcLwov"
      },
      "source": [
        "# Create a dataset of the text file strings\n",
        "\n",
        "text_files_dataset = tf.data.Dataset.from_tensor_slices(text_files)\n",
        "files = [file for file in text_files_dataset]\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGgRFvR_Lwox"
      },
      "source": [
        "# Interleave the lines from the text files\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x88YAMsuLwoz"
      },
      "source": [
        "# Print the first 10 elements of the interleaved dataset\n",
        "\n",
        "lines = [line for line in iter(interleaved_shakespeare_dataset.take(10))]\n",
        "for line in lines:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Px88RXmLwo0"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Training with Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfCscLFLLwo1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEq4s3oHLwo3"
      },
      "source": [
        "#### Load the UCI Bank Marketing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NukSa_ESmgRg"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1cNtP4iDyGhF620ZbmJdmJWYQrRgJTCum\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TD43V9imgeD"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mWVTUMGLwo4"
      },
      "source": [
        "# Load the CSV file into a pandas DataFrame\n",
        "\n",
        "bank_dataframe = pd.read_csv('path/to/bank/bank-full.csv', delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yhXvshyRLwo6"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "bank_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTEQWdkfLwo9"
      },
      "source": [
        "# Print the shape of the DataFrame\n",
        "\n",
        "print(bank_dataframe.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ORhBIMLwo_"
      },
      "source": [
        "# Select features from the DataFrame\n",
        "\n",
        "features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
        "            'loan', 'contact', 'campaign', 'pdays', 'poutcome']\n",
        "labels = ['y']\n",
        "\n",
        "bank_dataframe = bank_dataframe.filter(features + labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OvhQZha0LwpA"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "bank_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDGZ4VF-LwpC"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5OJBhpHLwpC"
      },
      "source": [
        "# Convert the categorical features in the DataFrame to one-hot encodings\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "categorical_features = ['default', 'housing', 'job', 'loan', 'education', 'contact', 'poutcome']\n",
        "\n",
        "for feature in categorical_features:\n",
        "    bank_dataframe[feature] = tuple(encoder.fit_transform(bank_dataframe[feature]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_H29rfTRLwpD"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "bank_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzA8Yfl7LwpE"
      },
      "source": [
        "# Shuffle the DataFrame\n",
        "\n",
        "bank_dataframe = bank_dataframe.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDCxC62VLwpF"
      },
      "source": [
        "#### Create the Dataset object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58t232NWLwpF"
      },
      "source": [
        "# Convert the DataFrame to a Dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIam8gBSLwpH"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0IxwSLpLwpN"
      },
      "source": [
        "#### Filter the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0m_HNo6LwpO"
      },
      "source": [
        "# First check that there are records in the dataset for non-married individuals\n",
        "\n",
        "def check_divorced():\n",
        "    bank_dataset_iterable = iter(bank_dataset)\n",
        "    for x in bank_dataset_iterable:\n",
        "        if x['marital'] != 'divorced':\n",
        "            print('Found a person with marital status: {}'.format(x['marital']))\n",
        "            return\n",
        "    print('No non-divorced people were found!')\n",
        "\n",
        "check_divorced()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dpKPS8vLwpP"
      },
      "source": [
        "# Filter the Dataset to retain only entries with a 'divorced' marital status\n",
        "\n",
        "bank_dataset = bank_dataset.filter(lambda x : tf.equal(x['marital'], tf.constant([b'divorced']))[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDqnULCjLwpR"
      },
      "source": [
        "# Check the records in the dataset again\n",
        "\n",
        "check_divorced()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ljy2Ro9LwpS"
      },
      "source": [
        "#### Map a function over the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qakJuUiNLwpS"
      },
      "source": [
        "# Convert the label ('y') to an integer instead of 'yes' or 'no'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1YcLNq7LwpT"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n",
        "bank_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bSkBnzlLwpV"
      },
      "source": [
        "# Remove the 'marital' column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lK3OmJ4LwpW"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n",
        "bank_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z_etyCZLwpZ"
      },
      "source": [
        "#### Create input and output data tuples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PStTjmKLwpZ"
      },
      "source": [
        "# Create an input and output tuple for the dataset\n",
        "\n",
        "def map_feature_label(x):\n",
        "    features = [[x['age']], [x['balance']], [x['campaign']], x['contact'], x['default'],\n",
        "                x['education'], x['housing'], x['job'], x['loan'], [x['pdays']], x['poutcome']]\n",
        "    return (tf.concat(features, axis=0), x['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pKehf3i-Lwpc"
      },
      "source": [
        "# Map this function over the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yet0K8SjLwpd"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7rFrXSkLwpf"
      },
      "source": [
        "#### Split into a training and a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u16htz4qLwpg"
      },
      "source": [
        "# Determine the length of the Dataset\n",
        "\n",
        "dataset_length = 0\n",
        "for _ in bank_dataset:\n",
        "    dataset_length += 1\n",
        "print(dataset_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFo3xsyQLwph"
      },
      "source": [
        "# Make training and validation sets from the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waZerBcdLwpj"
      },
      "source": [
        "#### Build a classification model\n",
        "\n",
        "Now let's build a model to classify the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMFNjG7PLwpj"
      },
      "source": [
        "# Build a classifier model\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(30,)))\n",
        "model.add(BatchNormalization(momentum=0.8))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(BatchNormalization(momentum=0.8))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(BatchNormalization(momentum=0.8))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ov8EijXLwpk"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VtbN-lMbLwpl"
      },
      "source": [
        "# Show the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6euItJ8bLwpn"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-gu3b4Lwpo"
      },
      "source": [
        "# Create batched training and validation datasets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSc4I6lhLwpp"
      },
      "source": [
        "# Shuffle the training data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BBzjSPpLLwpr"
      },
      "source": [
        "# Fit the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKUL_6uvLwps"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}